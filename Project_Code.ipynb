{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnwYIFKsUzwT",
        "outputId": "c53d84d2-d111-43b8-ee42-edfedb3b5112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 5000 samples\n",
            "Testing set: 999 samples\n",
            "Validation set: 983 samples\n",
            "Train - Negative: 1666, Positive: 1667, Neutral: 1667\n",
            "Test - Negative: 333, Positive: 333, Neutral: 333\n",
            "Val - Negative: 332, Positive: 318, Neutral: 333\n",
            "Datasets saved as CSV: train_dataset.csv, test_dataset.csv, val_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import csv\n",
        "\n",
        "# Function to generate the dataset with label noise\n",
        "def generate_large_dataset(label_noise_prob=0.15):  # Reduced from 0.2 to 0.15\n",
        "    subjects = [\n",
        "        \"I\", \"You\", \"He\", \"She\", \"We\", \"They\", \"The day\", \"My friend\", \"The movie\",\n",
        "        \"The weather\", \"Life\", \"Work\", \"School\", \"The team\", \"The food\", \"My phone\",\n",
        "        \"The game\", \"The trip\", \"This place\", \"That idea\", \"The book\", \"The party\",\n",
        "        \"The project\", \"The city\", \"The experience\"\n",
        "    ]\n",
        "    verbs = [\n",
        "        \"is\", \"feels\", \"seems\", \"looks\", \"was\", \"went\", \"sounds\", \"appears\",\n",
        "        \"has been\", \"will be\", \"turned out\", \"became\", \"remains\", \"gets\"\n",
        "    ]\n",
        "    positives = [\n",
        "        \"great\", \"awesome\", \"wonderful\", \"good\", \"fantastic\", \"amazing\", \"nice\",\n",
        "        \"perfect\", \"lovely\", \"excellent\", \"brilliant\", \"super\", \"fabulous\", \"cool\",\n",
        "        \"incredible\", \"enjoyable\", \"beautiful\", \"exciting\", \"happy\", \"pleasant\",\n",
        "        \"satisfying\", \"delightful\", \"impressive\", \"charming\", \"splendid\"\n",
        "    ]\n",
        "    negatives = [\n",
        "        \"bad\", \"terrible\", \"awful\", \"horrible\", \"poor\", \"lousy\", \"dreadful\", \"sad\",\n",
        "        \"miserable\", \"disappointing\", \"rotten\", \"pathetic\", \"annoying\", \"boring\",\n",
        "        \"frustrating\", \"ugly\", \"depressing\", \"lame\", \"unpleasant\", \"irritating\",\n",
        "        \"disastrous\", \"grim\", \"hopeless\", \"dull\", \"bleak\"\n",
        "    ]\n",
        "    neutrals = [\n",
        "        \"okay\", \"fine\", \"average\", \"so-so\", \"normal\", \"decent\", \"alright\", \"typical\",\n",
        "        \"nothing special\", \"fair\", \"passable\", \"mediocre\", \"standard\", \"plain\",\n",
        "        \"usual\", \"middling\", \"adequate\", \"not great\", \"not bad\", \"tolerable\",\n",
        "        \"acceptable\", \"unremarkable\", \"neutral\", \"moderate\", \"sufficient\"\n",
        "    ]\n",
        "    adverbs = [\n",
        "        \"really\", \"very\", \"quite\", \"pretty\", \"so\", \"totally\", \"somewhat\", \"kind of\",\n",
        "        \"a bit\", \"slightly\", \"\", \"\"  # Empty for natural variation\n",
        "    ]\n",
        "    connectors = [\n",
        "        \"and\", \"but\", \"because\", \"though\", \"since\", \"while\", \"yet\", \"\"\n",
        "    ]\n",
        "\n",
        "    simple_templates = [\n",
        "        \"{subject} {verb} {adverb} {sentiment}.\",\n",
        "        \"{subject} {verb} {sentiment} today.\",\n",
        "        \"{subject} {verb} {adverb} {sentiment} lately.\",\n",
        "        \"{subject} {verb} {sentiment} this week.\"\n",
        "    ]\n",
        "    question_templates = [\n",
        "        \"Is {subject} {adverb} {sentiment}?\",\n",
        "        \"Why {verb} {subject} {adverb} {sentiment}?\",\n",
        "        \"Does {subject} {verb} {sentiment}?\",\n",
        "        \"How {adverb} {sentiment} {verb} {subject}?\"\n",
        "    ]\n",
        "    exclamation_templates = [\n",
        "        \"Wow, {subject} {verb} {adverb} {sentiment}!\",\n",
        "        \"What a {sentiment} time {subject} {verb}!\",\n",
        "        \"So {sentiment} that {subject} {verb}!\",\n",
        "        \"How {sentiment} {subject} {verb}!\"\n",
        "    ]\n",
        "    compound_templates = [\n",
        "        \"{subject} {verb} {adverb} {sentiment} {connector} it’s fine.\",\n",
        "        \"I think {subject} {verb} {sentiment} {connector} that’s true.\",\n",
        "        \"{subject} {verb} {sentiment} {connector} I don’t mind.\",\n",
        "        \"{subject} {verb} {adverb} {sentiment} {connector} it could be worse.\"\n",
        "    ]\n",
        "\n",
        "    train_size, test_size, val_size = 5000, 1000, 1000\n",
        "    total_size = train_size + test_size + val_size  # 7000\n",
        "    train_per_class = 1667\n",
        "    test_val_per_class = 333\n",
        "    total_per_class = train_per_class + test_val_per_class + test_val_per_class\n",
        "\n",
        "    texts = []\n",
        "    labels = []\n",
        "\n",
        "    for sentiment_list, label in [(negatives, 0), (positives, 1), (neutrals, 2)]:\n",
        "        count = 0\n",
        "        while count < total_per_class:\n",
        "            template_type = random.random()\n",
        "            if template_type < 0.3:\n",
        "                template = random.choice(simple_templates)\n",
        "                sentence = template.format(\n",
        "                    subject=random.choice(subjects),\n",
        "                    verb=random.choice(verbs),\n",
        "                    adverb=random.choice(adverbs),\n",
        "                    sentiment=random.choice(sentiment_list)\n",
        "                )\n",
        "            elif template_type < 0.6:\n",
        "                template = random.choice(question_templates)\n",
        "                sentence = template.format(\n",
        "                    subject=random.choice(subjects),\n",
        "                    verb=random.choice(verbs),\n",
        "                    adverb=random.choice(adverbs),\n",
        "                    sentiment=random.choice(sentiment_list)\n",
        "                )\n",
        "            elif template_type < 0.8:\n",
        "                template = random.choice(exclamation_templates)\n",
        "                sentence = template.format(\n",
        "                    subject=random.choice(subjects),\n",
        "                    verb=random.choice(verbs),\n",
        "                    adverb=random.choice(adverbs),\n",
        "                    sentiment=random.choice(sentiment_list)\n",
        "                )\n",
        "            else:\n",
        "                template = random.choice(compound_templates)\n",
        "                sentence = template.format(\n",
        "                    subject=random.choice(subjects),\n",
        "                    verb=random.choice(verbs),\n",
        "                    adverb=random.choice(adverbs),\n",
        "                    sentiment=random.choice(sentiment_list),\n",
        "                    connector=random.choice(connectors)\n",
        "                )\n",
        "            if sentence not in texts and not (label == 1 and \"nothing\" in sentence.lower() and \"special\" not in sentence.lower()):\n",
        "                texts.append(sentence)\n",
        "                # Add label noise\n",
        "                if random.random() < label_noise_prob:\n",
        "                    noisy_label = random.choice([0, 1, 2])\n",
        "                    while noisy_label == label:  # Ensure the noisy label is different\n",
        "                        noisy_label = random.choice([0, 1, 2])\n",
        "                    labels.append(noisy_label)\n",
        "                else:\n",
        "                    labels.append(label)\n",
        "                count += 1\n",
        "\n",
        "    combined = list(zip(texts, labels))\n",
        "    random.shuffle(combined)\n",
        "    texts, labels = zip(*combined)\n",
        "    texts, labels = list(texts[:total_size]), list(labels[:total_size])\n",
        "\n",
        "    train_texts, train_labels = [], []\n",
        "    test_texts, test_labels = [], []\n",
        "    val_texts, val_labels = [], []\n",
        "\n",
        "    class_counts = {0: 0, 1: 0, 2: 0}\n",
        "    for text, label in zip(texts, labels):\n",
        "        if class_counts[label] < train_per_class:\n",
        "            train_texts.append(text)\n",
        "            train_labels.append(label)\n",
        "            class_counts[label] += 1\n",
        "        elif class_counts[label] < train_per_class + test_val_per_class:\n",
        "            test_texts.append(text)\n",
        "            test_labels.append(label)\n",
        "            class_counts[label] += 1\n",
        "        elif class_counts[label] < train_per_class + test_val_per_class + test_val_per_class:\n",
        "            val_texts.append(text)\n",
        "            val_labels.append(label)\n",
        "            class_counts[label] += 1\n",
        "\n",
        "    train_texts, train_labels = train_texts[:5000], train_labels[:5000]\n",
        "    test_texts, test_labels = test_texts[:1000], test_labels[:1000]\n",
        "    val_texts, val_labels = val_texts[:1000], val_labels[:1000]\n",
        "\n",
        "    return (train_texts, train_labels), (test_texts, test_labels), (val_texts, val_labels)\n",
        "\n",
        "# Save dataset to CSV files\n",
        "def save_dataset_to_csv(train_data, test_data, val_data):\n",
        "    def write_csv(filename, texts, labels):\n",
        "        with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(['text', 'label'])\n",
        "            for text, label in zip(texts, labels):\n",
        "                writer.writerow([text, label])\n",
        "\n",
        "    write_csv('train_dataset.csv', train_data[0], train_data[1])\n",
        "    write_csv('test_dataset.csv', test_data[0], test_data[1])\n",
        "    write_csv('val_dataset.csv', val_data[0], val_data[1])\n",
        "    print(\"Datasets saved as CSV: train_dataset.csv, test_dataset.csv, val_dataset.csv\")\n",
        "\n",
        "# Generate and save the dataset\n",
        "if __name__ == \"__main__\":\n",
        "    (train_texts, train_labels), (test_texts, test_labels), (val_texts, val_labels) = generate_large_dataset(label_noise_prob=0.15)\n",
        "\n",
        "    print(f\"Training set: {len(train_texts)} samples\")\n",
        "    print(f\"Testing set: {len(test_texts)} samples\")\n",
        "    print(f\"Validation set: {len(val_texts)} samples\")\n",
        "\n",
        "    for name, labels in [(\"Train\", train_labels), (\"Test\", test_labels), (\"Val\", val_labels)]:\n",
        "        neg = sum(1 for l in labels if l == 0)\n",
        "        pos = sum(1 for l in labels if l == 1)\n",
        "        neu = sum(1 for l in labels if l == 2)\n",
        "        print(f\"{name} - Negative: {neg}, Positive: {pos}, Neutral: {neu}\")\n",
        "\n",
        "    save_dataset_to_csv(\n",
        "        (train_texts, train_labels),\n",
        "        (test_texts, test_labels),\n",
        "        (val_texts, val_labels)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AiACKxWdU4ow",
        "outputId": "5caab447-c9f4-49a4-8be4-796505e2a0a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: gradio==4.44.0 in /usr/local/lib/python3.11/dist-packages (4.44.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (24.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (0.11.5)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (2.3.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.44.0) (0.34.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.3.0->gradio==4.44.0) (2024.10.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.3.0->gradio==4.44.0) (12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==4.44.0) (3.10)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1.0->gradio==4.44.0) (0.46.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.44.0) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.44.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.44.0) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==4.44.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==4.44.0) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.44.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.44.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.44.0) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.0) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install torch transformers datasets pandas numpy matplotlib seaborn gradio==4.44.0 scikit-learn openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R4VTzjw2T2lM",
        "outputId": "3a762ae4-b91a-428d-c537-48929dd617a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to initialize OpenAI API: OpenAI API key not found in environment variables.. Falling back to DistilBERT.\n",
            "Training a new model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total batches per epoch: 312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/4: 100%|██████████| 312/312 [00:52<00:00,  5.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4 completed, Avg Train Loss: 7.3546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 6.6555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/4: 100%|██████████| 312/312 [00:52<00:00,  5.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/4 completed, Avg Train Loss: 6.4623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 6.4318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/4: 100%|██████████| 312/312 [00:52<00:00,  5.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/4 completed, Avg Train Loss: 6.4817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 6.4593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/4: 100%|██████████| 312/312 [00:52<00:00,  5.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/4 completed, Avg Train Loss: 6.4150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 6.6125\n",
            "Creating Gradio interface...\n",
            "Created text_input, predict_btn, sentiment_output, and feedback_input\n",
            "Created feedback_btn, feedback_output, and retrain_status\n",
            "Created plot_output and update_plot_btn\n",
            "Set up predict_btn event handler\n",
            "Set up feedback_btn event handler\n",
            "Set up update_plot_btn event handler\n",
            "Set up demo.load for initial plot\n",
            "Gradio interface created successfully\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://68f426da14d62319e5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://68f426da14d62319e5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gradio as gr\n",
        "from transformers import AutoTokenizer, DistilBertForSequenceClassification, DistilBertConfig\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import openai\n",
        "from openai import OpenAIError\n",
        "\n",
        "# Set up the OpenAI API key (retrieve from environment variable or set directly)\n",
        "try:\n",
        "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not openai.api_key:\n",
        "        raise ValueError(\"OpenAI API key not found in environment variables.\")\n",
        "    client = openai.Client(api_key=openai.api_key)\n",
        "    USE_GPT4O = True\n",
        "    print(\"OpenAI API key found. GPT-4o will be used for sentiment analysis if available.\")\n",
        "except (ValueError, OpenAIError) as e:\n",
        "    print(f\"Failed to initialize OpenAI API: {e}. Falling back to DistilBERT.\")\n",
        "    USE_GPT4O = False\n",
        "\n",
        "# 1. Data Preparation\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if not isinstance(label, (int, np.integer)) or label < 0 or label > 2:\n",
        "            raise ValueError(f\"Invalid label at index {idx}: {label}. Must be an integer in [0, 2].\")\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].flatten()\n",
        "        attention_mask = encoding['attention_mask'].flatten()\n",
        "        if input_ids.shape != (self.max_length,) or attention_mask.shape != (self.max_length,):\n",
        "            raise ValueError(f\"Invalid encoding shape at index {idx}: input_ids {input_ids.shape}, attention_mask {attention_mask.shape}\")\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# 2. Model Setup with Dropout and Freezing Layers (Using DistilBERT)\n",
        "def initialize_model():\n",
        "    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "    config = DistilBertConfig.from_pretrained('distilbert-base-uncased', num_labels=3, dropout=0.3)\n",
        "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)\n",
        "\n",
        "    for param in model.distilbert.transformer.layer[:1].parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "# 3. Trainer with Human Feedback, Validation, and GPT-4o Integration\n",
        "class SentimentTrainer:\n",
        "    def __init__(self, model, tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model.to(self.device)\n",
        "        self.training_losses = []\n",
        "        self.validation_losses = []\n",
        "        self.feedback_data = []\n",
        "        self.feedback_predictions = []\n",
        "        self.all_feedback_predictions = []\n",
        "        self.accuracy_history = []\n",
        "        self.feedback_threshold = 5\n",
        "        self.loss_scale_factor = 12.0\n",
        "        self.min_loss_threshold = 3.0\n",
        "        self.val_loss_increase_tolerance = 0.05\n",
        "        self.min_epochs_before_stopping = 2\n",
        "\n",
        "    def train(self, train_dataset, val_dataset, epochs=4, batch_size=16, drop_last=True, lr=5e-5):\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=drop_last, num_workers=2)\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=lr, weight_decay=0.01)\n",
        "\n",
        "        self.model.train()\n",
        "        total_batches = len(train_dataloader)\n",
        "        print(f\"Total batches per epoch: {total_batches}\")\n",
        "\n",
        "        if total_batches == 0:\n",
        "            print(\"Warning: No batches to train on. Check dataset size and batch_size.\")\n",
        "            return self.training_losses, self.validation_losses\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            epoch_train_loss = 0\n",
        "            self.model.train()\n",
        "            for batch in tqdm(train_dataloader, total=total_batches, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
        "                optimizer.zero_grad()\n",
        "                input_ids = batch['input_ids'].to(self.device)\n",
        "                attention_mask = batch['attention_mask'].to(self.device)\n",
        "                labels = batch['labels'].to(self.device)\n",
        "\n",
        "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                scaled_loss = loss * self.loss_scale_factor\n",
        "                scaled_loss = torch.max(scaled_loss, torch.tensor(self.min_loss_threshold, device=self.device))\n",
        "                scaled_loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_train_loss += scaled_loss.item()\n",
        "\n",
        "            avg_train_loss = epoch_train_loss / total_batches\n",
        "            self.training_losses.append(avg_train_loss)\n",
        "            print(f\"Epoch {epoch + 1}/{epochs} completed, Avg Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "            self.model.eval()\n",
        "            epoch_val_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for batch in val_dataloader:\n",
        "                    input_ids = batch['input_ids'].to(self.device)\n",
        "                    attention_mask = batch['attention_mask'].to(self.device)\n",
        "                    labels = batch['labels'].to(self.device)\n",
        "                    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                    loss = outputs.loss\n",
        "                    scaled_loss = loss * self.loss_scale_factor\n",
        "                    scaled_loss = torch.max(scaled_loss, torch.tensor(self.min_loss_threshold, device=self.device))\n",
        "                    epoch_val_loss += scaled_loss.item()\n",
        "\n",
        "            avg_val_loss = epoch_val_loss / len(val_dataloader)\n",
        "            self.validation_losses.append(avg_val_loss)\n",
        "            print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "            if avg_val_loss < self.min_loss_threshold:\n",
        "                print(f\"Validation loss {avg_val_loss:.4f} below minimum threshold {self.min_loss_threshold}, stopping early.\")\n",
        "                break\n",
        "            if epoch > self.min_epochs_before_stopping:\n",
        "                prev_val_loss = self.validation_losses[epoch-1]\n",
        "                if avg_val_loss > prev_val_loss * (1 + self.val_loss_increase_tolerance):\n",
        "                    print(f\"Validation loss increased significantly (from {prev_val_loss:.4f} to {avg_val_loss:.4f}), stopping early.\")\n",
        "                    break\n",
        "\n",
        "        return self.training_losses, self.validation_losses\n",
        "\n",
        "    def retrain_with_feedback(self, batch_size=4):\n",
        "        print(f\"Checking feedback entries: {len(self.feedback_data)}\")\n",
        "        if len(self.feedback_data) < self.feedback_threshold:\n",
        "            print(f\"Feedback entries: {len(self.feedback_data)}. Need {self.feedback_threshold} to retrain.\")\n",
        "            return False\n",
        "\n",
        "        print(\"Retraining with human feedback...\")\n",
        "        feedback_texts = [item[0] for item in self.feedback_data]\n",
        "        feedback_labels = [item[1] for item in self.feedback_data]\n",
        "        feedback_dataset = SentimentDataset(feedback_texts, feedback_labels, self.tokenizer)\n",
        "        self.train(feedback_dataset, feedback_dataset, epochs=1, batch_size=batch_size, drop_last=False, lr=1e-5)\n",
        "        self.feedback_data = []\n",
        "        self.feedback_predictions = []\n",
        "        print(\"Feedback data and predictions cleared after retraining.\")\n",
        "        return True\n",
        "\n",
        "    def predict(self, text):\n",
        "        if not text.strip():\n",
        "            return 2, 0.5\n",
        "\n",
        "        if USE_GPT4O:\n",
        "            try:\n",
        "                prompt = f\"Classify the sentiment of the following text as 'positive', 'negative', or 'neutral':\\n\\n{text}\\n\\nReturn only the sentiment label (e.g., 'positive', 'negative', 'neutral').\"\n",
        "                response = client.chat.completions.create(\n",
        "                    model=\"gpt-4o\",\n",
        "                    messages=[\n",
        "                        {\"role\": \"system\", \"content\": \"You are a sentiment analysis expert.\"},\n",
        "                        {\"role\": \"user\", \"content\": prompt}\n",
        "                    ],\n",
        "                    max_tokens=10,\n",
        "                    temperature=0.0\n",
        "                )\n",
        "                gpt_sentiment = response.choices[0].message.content.strip().lower()\n",
        "                print(f\"GPT-4o predicted sentiment: {gpt_sentiment}\")\n",
        "\n",
        "                sentiment_map = {\"negative\": 0, \"positive\": 1, \"neutral\": 2}\n",
        "                if gpt_sentiment not in sentiment_map:\n",
        "                    raise ValueError(f\"Invalid sentiment returned by GPT-4o: {gpt_sentiment}\")\n",
        "\n",
        "                sentiment = sentiment_map[gpt_sentiment]\n",
        "                score = 0.9\n",
        "                print(f\"Input: {text}, Predicted (via GPT-4o): {sentiment}, Score: {score}\")\n",
        "                return sentiment, score\n",
        "\n",
        "            except (OpenAIError, ValueError, Exception) as e:\n",
        "                print(f\"Error using GPT-4o: {e}. Falling back to DistilBERT.\")\n",
        "\n",
        "        self.model.eval()\n",
        "        inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            sentiment = torch.argmax(probs, dim=-1).item()\n",
        "            score = probs[0][sentiment].item()\n",
        "            print(f\"Input: {text}, Probabilities: {probs.tolist()[0]}, Predicted (via DistilBERT): {sentiment}, Score: {score}\")\n",
        "            return sentiment, score\n",
        "\n",
        "    def add_feedback(self, text, human_label):\n",
        "        label_map = {\"Negative\": 0, \"Positive\": 1, \"Neutral\": 2}\n",
        "        print(f\"Received feedback for text: {text}, human_label: {human_label}\")\n",
        "        if human_label not in label_map:\n",
        "            print(f\"Invalid feedback label: {human_label}. Expected one of {list(label_map.keys())}\")\n",
        "            return False\n",
        "\n",
        "        pred_sentiment, pred_score = self.predict(text)\n",
        "        self.feedback_data.append((text, label_map[human_label]))\n",
        "        self.feedback_predictions.append((text, pred_sentiment, human_label))\n",
        "        self.all_feedback_predictions.append((text, pred_sentiment, human_label))\n",
        "        accuracy = self.calculate_accuracy()\n",
        "        self.accuracy_history.append(accuracy)\n",
        "        print(f\"Feedback added. Current feedback_data: {self.feedback_data}\")\n",
        "        print(f\"Current feedback_predictions: {self.feedback_predictions}\")\n",
        "        print(f\"All feedback predictions: {self.all_feedback_predictions}\")\n",
        "        print(f\"Accuracy history: {self.accuracy_history}\")\n",
        "        retrained = self.retrain_with_feedback()\n",
        "        return retrained\n",
        "\n",
        "    def calculate_accuracy(self):\n",
        "        if not self.all_feedback_predictions:\n",
        "            return 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for _, pred, feedback in self.all_feedback_predictions:\n",
        "            if pred == {\"Negative\": 0, \"Positive\": 1, \"Neutral\": 2}[feedback]:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "        return correct / total if total > 0 else 0\n",
        "\n",
        "# 4. Visualization with Validation Loss and Accuracy Line Graph (in Percentage)\n",
        "def create_visualizations(trainer):\n",
        "    plt.figure(figsize=(18, 4))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    if trainer.training_losses:\n",
        "        plt.plot(trainer.training_losses, 'b-o', label='Train Loss')\n",
        "        plt.plot(trainer.validation_losses, 'r-o', label='Val Loss')\n",
        "        plt.legend()\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    if trainer.all_feedback_predictions:\n",
        "        scores = [trainer.predict(text)[1] for text, _, _ in trainer.all_feedback_predictions]\n",
        "        sns.histplot(scores, bins=20)\n",
        "    plt.title('Sentiment Predictions (Feedback)')\n",
        "    plt.xlabel('Score')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    if trainer.accuracy_history:\n",
        "        accuracy_percent = [acc * 100 for acc in trainer.accuracy_history]\n",
        "        plt.plot(accuracy_percent, 'g-o', label='Accuracy (%)')\n",
        "        plt.legend()\n",
        "        plt.ylim(0, 110)  # Adjusted upper limit to 110 to make 100% visible\n",
        "        plt.ylabel('Accuracy (%)')\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'No feedback yet', ha='center')\n",
        "    plt.title('Accuracy Over Feedback Cycles')\n",
        "    plt.xlabel('Feedback Entry')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return plt\n",
        "\n",
        "# 5. Gradio Interface (Updated Title and Centered Alignment)\n",
        "def create_interface(trainer):\n",
        "    # Custom CSS to reduce padding, margins, and center the title\n",
        "    custom_css = \"\"\"\n",
        "    .gr-column {\n",
        "        padding: 5px !important;\n",
        "        margin: 0 !important;\n",
        "        display: flex !important;\n",
        "        flex-direction: column !important;\n",
        "    }\n",
        "    .gr-textbox, .gr-radio, .gr-button {\n",
        "        margin-bottom: 5px !important;\n",
        "    }\n",
        "    .update-visualizations-container {\n",
        "        display: flex !important;\n",
        "        justify-content: center !important;\n",
        "        margin-top: 10px !important;\n",
        "    }\n",
        "    .title {\n",
        "        text-align: center !important;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    def predict_sentiment(text):\n",
        "        print(\"Predict Sentiment called with text:\", text)\n",
        "        sentiment, score = trainer.predict(text)\n",
        "        sentiment_map = {0: \"Negative\", 1: \"Positive\", 2: \"Neutral\"}\n",
        "        return f\"Sentiment: {sentiment_map[sentiment]} (Score: {score:.3f})\"\n",
        "\n",
        "    def provide_feedback(text, feedback):\n",
        "        print(\"Provide Feedback called with text:\", text, \"feedback:\", feedback)\n",
        "        if feedback is None:\n",
        "            return \"Please select a feedback option\", None, \"\"\n",
        "        print(f\"Gradio feedback received: text={text}, feedback={feedback}\")\n",
        "        retrained = trainer.add_feedback(text, feedback)\n",
        "        updated_plot = create_visualizations(trainer)\n",
        "        retrain_message = \"Retraining triggered after 5th feedback!\" if retrained else \"\"\n",
        "        return f\"Feedback recorded: {feedback}\", updated_plot, retrain_message\n",
        "\n",
        "    with gr.Blocks(css=custom_css, analytics_enabled=False) as demo:  # Disable analytics\n",
        "        print(\"Creating Gradio interface...\")\n",
        "        gr.Markdown(\n",
        "            \"# Fine-Tuning Language Model for Sentiment Analysis with Feedback Loop\",\n",
        "            elem_classes=[\"title\"]\n",
        "        )\n",
        "\n",
        "        # Main layout: Row with two columns, redistributed components\n",
        "        with gr.Row():\n",
        "            with gr.Column(variant=\"compact\", scale=1):\n",
        "                text_input = gr.Textbox(label=\"Enter text\", lines=1)\n",
        "                predict_btn = gr.Button(\"Analyze\")\n",
        "                sentiment_output = gr.Textbox(\n",
        "                    label=\"Prediction\",\n",
        "                    interactive=False,\n",
        "                    lines=1\n",
        "                )\n",
        "                feedback_input = gr.Radio(\n",
        "                    [\"Positive\", \"Negative\", \"Neutral\"],\n",
        "                    label=\"Your Feedback\",\n",
        "                    min_width=200\n",
        "                )\n",
        "                print(\"Created text_input, predict_btn, sentiment_output, and feedback_input\")\n",
        "            with gr.Column(variant=\"compact\", scale=1):\n",
        "                feedback_btn = gr.Button(\"Submit Feedback\")\n",
        "                feedback_output = gr.Textbox(\n",
        "                    label=\"Feedback Status\",\n",
        "                    interactive=False,\n",
        "                    min_width=200,\n",
        "                    lines=2\n",
        "                )\n",
        "                retrain_status = gr.Textbox(\n",
        "                    label=\"Retraining Status\",\n",
        "                    interactive=False,\n",
        "                    min_width=200,\n",
        "                    lines=5\n",
        "                )\n",
        "                print(\"Created feedback_btn, feedback_output, and retrain_status\")\n",
        "\n",
        "        # Visualizations section (below the row)\n",
        "        plot_output = gr.Plot(label=\"Visualizations\")\n",
        "        # Center the Update Visualizations button\n",
        "        with gr.Group(elem_classes=[\"update-visualizations-container\"]):\n",
        "            update_plot_btn = gr.Button(\"Update Visualizations\")\n",
        "        print(\"Created plot_output and update_plot_btn\")\n",
        "\n",
        "        # Set up event handlers\n",
        "        predict_btn.click(\n",
        "            fn=predict_sentiment,\n",
        "            inputs=text_input,\n",
        "            outputs=sentiment_output\n",
        "        )\n",
        "        print(\"Set up predict_btn event handler\")\n",
        "\n",
        "        feedback_btn.click(\n",
        "            fn=provide_feedback,\n",
        "            inputs=[text_input, feedback_input],\n",
        "            outputs=[feedback_output, plot_output, retrain_status]\n",
        "        )\n",
        "        print(\"Set up feedback_btn event handler\")\n",
        "\n",
        "        update_plot_btn.click(\n",
        "            fn=lambda: create_visualizations(trainer),\n",
        "            outputs=plot_output\n",
        "        )\n",
        "        print(\"Set up update_plot_btn event handler\")\n",
        "\n",
        "        # Initialize the plot on launch\n",
        "        demo.load(\n",
        "            fn=lambda: create_visualizations(trainer),\n",
        "            outputs=plot_output\n",
        "        )\n",
        "        print(\"Set up demo.load for initial plot\")\n",
        "\n",
        "    print(\"Gradio interface created successfully\")\n",
        "    return demo\n",
        "\n",
        "# 6. Main Function (Updated to Remove Model Saving/Loading)\n",
        "def main():\n",
        "    # Load datasets\n",
        "    for file in ['train_dataset.csv', 'test_dataset.csv', 'val_dataset.csv']:\n",
        "        if not os.path.exists(file):\n",
        "            raise FileNotFoundError(f\"Dataset file {file} not found. Please run the dataset generation script first.\")\n",
        "\n",
        "    train_df = pd.read_csv('train_dataset.csv')\n",
        "    val_df = pd.read_csv('val_dataset.csv')\n",
        "\n",
        "    train_texts, train_labels = train_df['text'].tolist(), train_df['label'].tolist()\n",
        "    val_texts, val_labels = val_df['text'].tolist(), val_df['label'].tolist()\n",
        "\n",
        "    # Initialize a new model (no loading)\n",
        "    print(\"Training a new model...\")\n",
        "    model, tokenizer = initialize_model()\n",
        "\n",
        "    # Initialize the trainer\n",
        "    train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
        "    val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n",
        "    trainer = SentimentTrainer(model, tokenizer)\n",
        "\n",
        "    # Train the model (no saving/loading of trainer state)\n",
        "    trainer.train(train_dataset, val_dataset, epochs=4, batch_size=16)\n",
        "\n",
        "    # Launch the Gradio interface\n",
        "    interface = create_interface(trainer)\n",
        "    interface.launch()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}